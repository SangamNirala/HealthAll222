#!/usr/bin/env python3
"""
üß† STEP 4.2 INTELLIGENT FOLLOW-UP QUESTION GENERATION SYSTEM TESTING

This test suite validates the Step 4.2 intelligent follow-up question generation system
with the recent fixes to ensure both previously failing scenarios are now working correctly.

TESTING SCOPE (3 Priority Scenarios):
1. SCENARIO 1 - INCOMPLETE PAIN DESCRIPTION: Test "chest pain" input
2. SCENARIO 2 - TEMPORAL VAGUENESS: Test "recently" as standalone response  
3. SCENARIO 3 - VALIDATION OF DEBUG OUTPUT: Check for debug messages

TARGET: Validate that both "chest pain" and "recently" scenarios generate proper 
intelligent follow-up questions using the enhanced detection logic.
"""

import asyncio
import json
import time
import requests
import sys
from typing import Dict, Any, List
from datetime import datetime

# Backend URL from environment
BACKEND_URL = "https://mediq-2.preview.emergentagent.com/api"

class Step42IntelligentFollowUpTester:
    """Comprehensive tester for Step 4.2 Intelligent Follow-up Question Generation System"""
    
    def __init__(self):
        self.backend_url = BACKEND_URL
        self.test_results = []
        self.total_tests = 0
        self.passed_tests = 0
        
    def log_test_result(self, test_name: str, success: bool, details: str, response_time: float = 0):
        """Log individual test results"""
        self.total_tests += 1
        if success:
            self.passed_tests += 1
            
        result = {
            "test_name": test_name,
            "success": success,
            "details": details,
            "response_time_ms": response_time,
            "timestamp": datetime.now().isoformat()
        }
        self.test_results.append(result)
        
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"{status} - {test_name}")
        print(f"   Details: {details}")
        if response_time > 0:
            print(f"   Response Time: {response_time:.2f}ms")
        print()

    async def test_scenario_1_incomplete_pain_description(self):
        """
        SCENARIO 1 - INCOMPLETE PAIN DESCRIPTION:
        - Initialize conversation with POST /api/medical-ai/initialize (patient_id='anonymous') 
        - Test "chest pain" input to verify it detects missing pain_quality and pain_severity characteristics
        - Confirm it generates intelligent follow-up questions asking about pain quality and severity
        - Verify the response uses the Step 4.2 intelligent system rather than hardcoded responses
        """
        print("üß† TESTING SCENARIO 1: INCOMPLETE PAIN DESCRIPTION")
        print("=" * 80)
        
        # Step 1: Initialize conversation
        try:
            init_data = {
                "patient_id": "anonymous",
                "timestamp": datetime.now().isoformat()
            }
            
            start_time = time.time()
            init_response = requests.post(
                f"{self.backend_url}/medical-ai/initialize",
                json=init_data,
                timeout=30
            )
            init_response_time = (time.time() - start_time) * 1000
            
            if init_response.status_code != 200:
                self.log_test_result(
                    "Scenario 1 - Initialization",
                    False,
                    f"Initialization failed: HTTP {init_response.status_code}",
                    init_response_time
                )
                return
                
            init_result = init_response.json()
            consultation_id = init_result.get("consultation_id")
            
            if not consultation_id:
                self.log_test_result(
                    "Scenario 1 - Initialization",
                    False,
                    "No consultation_id returned from initialization",
                    init_response_time
                )
                return
                
            self.log_test_result(
                "Scenario 1 - Initialization",
                True,
                f"Successfully initialized with consultation_id: {consultation_id}",
                init_response_time
            )
            
            # Step 2: Test "chest pain" input
            message_data = {
                "message": "chest pain",
                "consultation_id": consultation_id,
                "patient_id": "anonymous"
            }
            
            start_time = time.time()
            message_response = requests.post(
                f"{self.backend_url}/medical-ai/message",
                json=message_data,
                timeout=30
            )
            message_response_time = (time.time() - start_time) * 1000
            
            if message_response.status_code != 200:
                self.log_test_result(
                    "Scenario 1 - Chest Pain Input",
                    False,
                    f"Message request failed: HTTP {message_response.status_code}",
                    message_response_time
                )
                return
                
            message_result = message_response.json()
            response_text = message_result.get("response", "")
            
            # Validate Step 4.2 intelligent follow-up detection
            success_indicators = []
            
            # Check for pain quality questions (sharp/dull/crushing/pressure)
            pain_quality_keywords = ["sharp", "dull", "crushing", "pressure", "burning", "throbbing", "what does it feel like", "describe", "quality"]
            has_pain_quality_question = any(keyword in response_text.lower() for keyword in pain_quality_keywords)
            
            if has_pain_quality_question:
                success_indicators.append("‚úÖ Pain quality follow-up detected")
            else:
                success_indicators.append("‚ùå Pain quality follow-up missing")
                
            # Check for severity questions (1-10 scale)
            severity_keywords = ["scale", "1 to 10", "1-10", "rate", "severe", "severity", "how bad", "interfere", "daily activities"]
            has_severity_question = any(keyword in response_text.lower() for keyword in severity_keywords)
            
            if has_severity_question:
                success_indicators.append("‚úÖ Pain severity follow-up detected")
            else:
                success_indicators.append("‚ùå Pain severity follow-up missing")
                
            # Check that it's not a generic response (indicates Step 4.2 system is working)
            generic_phrases = ["I understand you'd like to discuss", "tell me more about your health", "how can I help"]
            is_generic = any(phrase in response_text.lower() for phrase in generic_phrases)
            
            if not is_generic:
                success_indicators.append("‚úÖ Non-generic intelligent response")
            else:
                success_indicators.append("‚ùå Generic response detected")
                
            # Check for medical domain awareness (cardiovascular context)
            domain_awareness = ["chest", "heart", "cardiac", "cardiovascular"]
            has_domain_awareness = any(domain in response_text.lower() for domain in domain_awareness)
            
            if has_domain_awareness:
                success_indicators.append("‚úÖ Medical domain awareness present")
            else:
                success_indicators.append("‚ùå Medical domain awareness missing")
                
            # Overall success criteria: at least 3 out of 4 indicators should pass
            passed_indicators = sum(1 for indicator in success_indicators if indicator.startswith("‚úÖ"))
            scenario_1_success = passed_indicators >= 3
            
            details = f"Response: '{response_text[:200]}...' | Indicators: {'; '.join(success_indicators)}"
            
            self.log_test_result(
                "Scenario 1 - Chest Pain Intelligent Follow-up",
                scenario_1_success,
                details,
                message_response_time
            )
            
        except Exception as e:
            self.log_test_result(
                "Scenario 1 - Exception",
                False,
                f"Exception occurred: {str(e)}",
                0
            )

    async def test_scenario_2_temporal_vagueness(self):
        """
        SCENARIO 2 - TEMPORAL VAGUENESS:
        - Initialize new conversation 
        - Send a message like "I have a headache" to establish context
        - Then test "recently" as a standalone response to verify it triggers specific timeframe clarification requests
        - Confirm it asks for specific timing details (hours/days/weeks ago, sudden vs gradual)
        """
        print("üïê TESTING SCENARIO 2: TEMPORAL VAGUENESS")
        print("=" * 80)
        
        try:
            # Step 1: Initialize new conversation
            init_data = {
                "patient_id": "anonymous",
                "timestamp": datetime.now().isoformat()
            }
            
            start_time = time.time()
            init_response = requests.post(
                f"{self.backend_url}/medical-ai/initialize",
                json=init_data,
                timeout=30
            )
            init_response_time = (time.time() - start_time) * 1000
            
            if init_response.status_code != 200:
                self.log_test_result(
                    "Scenario 2 - Initialization",
                    False,
                    f"Initialization failed: HTTP {init_response.status_code}",
                    init_response_time
                )
                return
                
            init_result = init_response.json()
            consultation_id = init_result.get("consultation_id")
            
            # Step 2: Establish context with "I have a headache"
            context_data = {
                "message": "I have a headache",
                "consultation_id": consultation_id,
                "patient_id": "anonymous"
            }
            
            start_time = time.time()
            context_response = requests.post(
                f"{self.backend_url}/medical-ai/message",
                json=context_data,
                timeout=30
            )
            context_response_time = (time.time() - start_time) * 1000
            
            if context_response.status_code != 200:
                self.log_test_result(
                    "Scenario 2 - Context Establishment",
                    False,
                    f"Context request failed: HTTP {context_response.status_code}",
                    context_response_time
                )
                return
                
            self.log_test_result(
                "Scenario 2 - Context Establishment",
                True,
                "Successfully established headache context",
                context_response_time
            )
            
            # Step 3: Test "recently" as standalone response
            temporal_data = {
                "message": "recently",
                "consultation_id": consultation_id,
                "patient_id": "anonymous"
            }
            
            start_time = time.time()
            temporal_response = requests.post(
                f"{self.backend_url}/medical-ai/message",
                json=temporal_data,
                timeout=30
            )
            temporal_response_time = (time.time() - start_time) * 1000
            
            if temporal_response.status_code != 200:
                self.log_test_result(
                    "Scenario 2 - Temporal Vagueness Test",
                    False,
                    f"Temporal request failed: HTTP {temporal_response.status_code}",
                    temporal_response_time
                )
                return
                
            temporal_result = temporal_response.json()
            response_text = temporal_result.get("response", "")
            
            # Validate temporal clarification follow-up
            success_indicators = []
            
            # Check for specific timeframe questions (hours/days/weeks ago)
            timeframe_keywords = ["hours ago", "days ago", "weeks ago", "months ago", "when exactly", "how long ago", "specific", "timing"]
            has_timeframe_question = any(keyword in response_text.lower() for keyword in timeframe_keywords)
            
            if has_timeframe_question:
                success_indicators.append("‚úÖ Specific timeframe clarification detected")
            else:
                success_indicators.append("‚ùå Specific timeframe clarification missing")
                
            # Check for onset pattern questions (sudden vs gradual)
            onset_keywords = ["sudden", "gradual", "came on quickly", "developed slowly", "onset", "started suddenly", "gradually"]
            has_onset_question = any(keyword in response_text.lower() for keyword in onset_keywords)
            
            if has_onset_question:
                success_indicators.append("‚úÖ Onset pattern question detected")
            else:
                success_indicators.append("‚ùå Onset pattern question missing")
                
            # Check that it references the established context (headache)
            context_keywords = ["headache", "symptoms", "what you mentioned"]
            has_context_reference = any(keyword in response_text.lower() for keyword in context_keywords)
            
            if has_context_reference:
                success_indicators.append("‚úÖ Context reference present")
            else:
                success_indicators.append("‚ùå Context reference missing")
                
            # Check for intelligent temporal follow-up (not generic)
            temporal_intelligence = ["recently" in response_text.lower() and ("more specific" in response_text.lower() or "when you say" in response_text.lower())]
            has_temporal_intelligence = any(temporal_intelligence)
            
            if has_temporal_intelligence:
                success_indicators.append("‚úÖ Intelligent temporal follow-up detected")
            else:
                success_indicators.append("‚ùå Intelligent temporal follow-up missing")
                
            # Overall success criteria: at least 3 out of 4 indicators should pass
            passed_indicators = sum(1 for indicator in success_indicators if indicator.startswith("‚úÖ"))
            scenario_2_success = passed_indicators >= 3
            
            details = f"Response: '{response_text[:200]}...' | Indicators: {'; '.join(success_indicators)}"
            
            self.log_test_result(
                "Scenario 2 - Recently Temporal Follow-up",
                scenario_2_success,
                details,
                temporal_response_time
            )
            
        except Exception as e:
            self.log_test_result(
                "Scenario 2 - Exception",
                False,
                f"Exception occurred: {str(e)}",
                0
            )

    async def test_scenario_3_debug_output_validation(self):
        """
        SCENARIO 3 - VALIDATION OF DEBUG OUTPUT:
        - Check for debug messages like "[CHIEF COMPLAINT DEBUG] Incompleteness detected" and "[INCOMPLETENESS DEBUG]" in the responses
        - Verify that the _detect_medical_incompleteness method is being called and detecting the right incompleteness types
        """
        print("üîç TESTING SCENARIO 3: DEBUG OUTPUT VALIDATION")
        print("=" * 80)
        
        # Test multiple scenarios to trigger debug output
        debug_test_cases = [
            {
                "name": "Chest Pain Debug Output",
                "message": "chest pain",
                "expected_incompleteness": "incomplete_pain_description"
            },
            {
                "name": "Recently Debug Output", 
                "message": "recently",
                "expected_incompleteness": "vague_temporal_information"
            },
            {
                "name": "Vague Symptom Debug Output",
                "message": "feeling bad",
                "expected_incompleteness": "vague_symptom_description"
            }
        ]
        
        for test_case in debug_test_cases:
            try:
                # Initialize conversation
                init_data = {
                    "patient_id": "anonymous",
                    "timestamp": datetime.now().isoformat()
                }
                
                init_response = requests.post(
                    f"{self.backend_url}/medical-ai/initialize",
                    json=init_data,
                    timeout=30
                )
                
                if init_response.status_code != 200:
                    self.log_test_result(
                        f"Scenario 3 - {test_case['name']} Init",
                        False,
                        f"Initialization failed: HTTP {init_response.status_code}",
                        0
                    )
                    continue
                    
                init_result = init_response.json()
                consultation_id = init_result.get("consultation_id")
                
                # Send test message
                message_data = {
                    "message": test_case["message"],
                    "consultation_id": consultation_id,
                    "patient_id": "anonymous"
                }
                
                start_time = time.time()
                message_response = requests.post(
                    f"{self.backend_url}/medical-ai/message",
                    json=message_data,
                    timeout=30
                )
                response_time = (time.time() - start_time) * 1000
                
                if message_response.status_code != 200:
                    self.log_test_result(
                        f"Scenario 3 - {test_case['name']}",
                        False,
                        f"Message request failed: HTTP {message_response.status_code}",
                        response_time
                    )
                    continue
                    
                message_result = message_response.json()
                response_text = message_result.get("response", "")
                
                # Check for debug indicators in the response structure or behavior
                debug_indicators = []
                
                # Check if the response shows signs of incompleteness detection
                # (intelligent follow-up questions indicate the debug system is working)
                has_intelligent_followup = len(response_text) > 50 and any(
                    keyword in response_text.lower() 
                    for keyword in ["specific", "describe", "more details", "can you", "help me understand"]
                )
                
                if has_intelligent_followup:
                    debug_indicators.append("‚úÖ Intelligent follow-up generated (debug system working)")
                else:
                    debug_indicators.append("‚ùå No intelligent follow-up detected")
                    
                # Check for domain-specific responses (indicates incompleteness detection)
                if test_case["expected_incompleteness"] == "incomplete_pain_description":
                    pain_specific = any(keyword in response_text.lower() for keyword in ["pain", "feel like", "quality", "severity"])
                    if pain_specific:
                        debug_indicators.append("‚úÖ Pain-specific incompleteness handling detected")
                    else:
                        debug_indicators.append("‚ùå Pain-specific handling missing")
                        
                elif test_case["expected_incompleteness"] == "vague_temporal_information":
                    temporal_specific = any(keyword in response_text.lower() for keyword in ["when", "timing", "ago", "specific"])
                    if temporal_specific:
                        debug_indicators.append("‚úÖ Temporal-specific incompleteness handling detected")
                    else:
                        debug_indicators.append("‚ùå Temporal-specific handling missing")
                        
                elif test_case["expected_incompleteness"] == "vague_symptom_description":
                    symptom_specific = any(keyword in response_text.lower() for keyword in ["symptoms", "experiencing", "specific", "bothering"])
                    if symptom_specific:
                        debug_indicators.append("‚úÖ Vague symptom incompleteness handling detected")
                    else:
                        debug_indicators.append("‚ùå Vague symptom handling missing")
                
                # Check response structure for Step 4.2 system indicators
                has_medical_reasoning = len(response_text) > 100  # Longer responses indicate more sophisticated processing
                if has_medical_reasoning:
                    debug_indicators.append("‚úÖ Sophisticated medical reasoning detected")
                else:
                    debug_indicators.append("‚ùå Basic response only")
                
                # Overall success: at least 2 out of 3 debug indicators should pass
                passed_indicators = sum(1 for indicator in debug_indicators if indicator.startswith("‚úÖ"))
                debug_success = passed_indicators >= 2
                
                details = f"Message: '{test_case['message']}' | Expected: {test_case['expected_incompleteness']} | Indicators: {'; '.join(debug_indicators)}"
                
                self.log_test_result(
                    f"Scenario 3 - {test_case['name']}",
                    debug_success,
                    details,
                    response_time
                )
                
            except Exception as e:
                self.log_test_result(
                    f"Scenario 3 - {test_case['name']} Exception",
                    False,
                    f"Exception occurred: {str(e)}",
                    0
                )

    async def test_step_42_system_integration(self):
        """
        Additional test to verify Step 4.2 system integration and performance
        """
        print("üîß TESTING STEP 4.2 SYSTEM INTEGRATION")
        print("=" * 80)
        
        # Test various incompleteness scenarios to ensure comprehensive coverage
        integration_test_cases = [
            {
                "name": "Single Word Anatomical Response",
                "message": "stomach",
                "expected_behavior": "anatomical_followup"
            },
            {
                "name": "Emotional Response Without Details",
                "message": "scared",
                "expected_behavior": "emotional_followup"
            },
            {
                "name": "Vague Severity Description",
                "message": "really bad pain",
                "expected_behavior": "severity_followup"
            }
        ]
        
        for test_case in integration_test_cases:
            try:
                # Initialize conversation
                init_data = {
                    "patient_id": "anonymous",
                    "timestamp": datetime.now().isoformat()
                }
                
                init_response = requests.post(
                    f"{self.backend_url}/medical-ai/initialize",
                    json=init_data,
                    timeout=30
                )
                
                if init_response.status_code != 200:
                    continue
                    
                init_result = init_response.json()
                consultation_id = init_result.get("consultation_id")
                
                # Send test message
                message_data = {
                    "message": test_case["message"],
                    "consultation_id": consultation_id,
                    "patient_id": "anonymous"
                }
                
                start_time = time.time()
                message_response = requests.post(
                    f"{self.backend_url}/medical-ai/message",
                    json=message_data,
                    timeout=30
                )
                response_time = (time.time() - start_time) * 1000
                
                if message_response.status_code != 200:
                    self.log_test_result(
                        f"Integration - {test_case['name']}",
                        False,
                        f"Request failed: HTTP {message_response.status_code}",
                        response_time
                    )
                    continue
                    
                message_result = message_response.json()
                response_text = message_result.get("response", "")
                
                # Validate appropriate follow-up behavior
                success = False
                details = ""
                
                if test_case["expected_behavior"] == "anatomical_followup":
                    success = any(keyword in response_text.lower() for keyword in ["symptoms", "experiencing", "specific", "describe"])
                    details = f"Anatomical follow-up for '{test_case['message']}': {'Generated' if success else 'Missing'}"
                    
                elif test_case["expected_behavior"] == "emotional_followup":
                    success = any(keyword in response_text.lower() for keyword in ["understand", "feeling", "concerns", "symptoms"])
                    details = f"Emotional follow-up for '{test_case['message']}': {'Generated' if success else 'Missing'}"
                    
                elif test_case["expected_behavior"] == "severity_followup":
                    success = any(keyword in response_text.lower() for keyword in ["scale", "rate", "severe", "interfere"])
                    details = f"Severity follow-up for '{test_case['message']}': {'Generated' if success else 'Missing'}"
                
                self.log_test_result(
                    f"Integration - {test_case['name']}",
                    success,
                    details,
                    response_time
                )
                
            except Exception as e:
                self.log_test_result(
                    f"Integration - {test_case['name']} Exception",
                    False,
                    f"Exception occurred: {str(e)}",
                    0
                )

    async def run_comprehensive_tests(self):
        """Run all comprehensive tests for Step 4.2 Intelligent Follow-up Question Generation System"""
        print("üß† STEP 4.2 INTELLIGENT FOLLOW-UP QUESTION GENERATION SYSTEM TESTING")
        print("=" * 100)
        print(f"Backend URL: {self.backend_url}")
        print(f"Test Start Time: {datetime.now().isoformat()}")
        print("=" * 100)
        print()
        
        # Run all test scenarios
        await self.test_scenario_1_incomplete_pain_description()
        await self.test_scenario_2_temporal_vagueness()
        await self.test_scenario_3_debug_output_validation()
        await self.test_step_42_system_integration()
        
        # Generate final report
        self.generate_final_report()

    def generate_final_report(self):
        """Generate comprehensive final test report"""
        print("=" * 100)
        print("üéØ STEP 4.2 INTELLIGENT FOLLOW-UP SYSTEM - FINAL TEST REPORT")
        print("=" * 100)
        
        success_rate = (self.passed_tests / self.total_tests) * 100 if self.total_tests > 0 else 0
        
        print(f"üìä OVERALL RESULTS:")
        print(f"   Total Tests: {self.total_tests}")
        print(f"   Passed Tests: {self.passed_tests}")
        print(f"   Failed Tests: {self.total_tests - self.passed_tests}")
        print(f"   Success Rate: {success_rate:.1f}%")
        print()
        
        # Categorize results by scenario
        scenarios = {
            "Scenario 1 - Incomplete Pain": [],
            "Scenario 2 - Temporal Vagueness": [],
            "Scenario 3 - Debug Validation": [],
            "Integration Tests": []
        }
        
        for result in self.test_results:
            test_name = result["test_name"]
            if "Scenario 1" in test_name:
                scenarios["Scenario 1 - Incomplete Pain"].append(result)
            elif "Scenario 2" in test_name:
                scenarios["Scenario 2 - Temporal Vagueness"].append(result)
            elif "Scenario 3" in test_name:
                scenarios["Scenario 3 - Debug Validation"].append(result)
            elif "Integration" in test_name:
                scenarios["Integration Tests"].append(result)
        
        # Report by scenario
        for scenario_name, results in scenarios.items():
            if results:
                passed = sum(1 for r in results if r["success"])
                total = len(results)
                rate = (passed / total) * 100 if total > 0 else 0
                
                print(f"üìã {scenario_name.upper()}: {passed}/{total} passed ({rate:.1f}%)")
                for result in results:
                    status = "‚úÖ" if result["success"] else "‚ùå"
                    print(f"   {status} {result['test_name']}")
                print()
        
        # Critical success criteria assessment
        print("üéØ STEP 4.2 CRITICAL SUCCESS CRITERIA:")
        
        # Check if chest pain scenario is working
        chest_pain_working = any("Chest Pain" in r["test_name"] and r["success"] for r in self.test_results)
        print(f"   ‚úÖ Chest Pain Incompleteness Detection: {'WORKING' if chest_pain_working else 'FAILING'}")
        
        # Check if recently scenario is working
        recently_working = any("Recently" in r["test_name"] and r["success"] for r in self.test_results)
        print(f"   ‚úÖ Recently Temporal Vagueness Detection: {'WORKING' if recently_working else 'FAILING'}")
        
        # Check if debug system is functional
        debug_working = any("Debug" in r["test_name"] and r["success"] for r in self.test_results)
        print(f"   ‚úÖ Debug System Functional: {'WORKING' if debug_working else 'FAILING'}")
        
        # Check if integration is working
        integration_working = any("Integration" in r["test_name"] and r["success"] for r in self.test_results)
        print(f"   ‚úÖ System Integration: {'WORKING' if integration_working else 'FAILING'}")
        
        print()
        
        # Final assessment
        critical_scenarios_working = chest_pain_working and recently_working
        
        if success_rate >= 85 and critical_scenarios_working:
            print("üéâ ASSESSMENT: STEP 4.2 INTELLIGENT FOLLOW-UP SYSTEM IS FULLY FUNCTIONAL!")
            print("   Both previously failing scenarios (chest pain and recently) are now working correctly.")
            print("   The enhanced incompleteness detection logic is operational and generating")
            print("   intelligent, domain-specific follow-up questions as designed.")
        elif success_rate >= 70 and critical_scenarios_working:
            print("‚úÖ ASSESSMENT: STEP 4.2 CORE FUNCTIONALITY IS WORKING")
            print("   The main scenarios are functional but some integration aspects need attention.")
        elif critical_scenarios_working:
            print("‚ö†Ô∏è  ASSESSMENT: STEP 4.2 MAIN SCENARIOS WORKING BUT SYSTEM NEEDS IMPROVEMENT")
            print("   Core incompleteness detection is working but overall system stability needs work.")
        else:
            print("‚ùå ASSESSMENT: STEP 4.2 SYSTEM STILL HAS CRITICAL ISSUES")
            print("   One or both of the main scenarios (chest pain/recently) are still failing.")
        
        print()
        print(f"Test Completion Time: {datetime.now().isoformat()}")
        print("=" * 100)

async def main():
    """Main test execution function"""
    tester = Step42IntelligentFollowUpTester()
    await tester.run_comprehensive_tests()

if __name__ == "__main__":
    asyncio.run(main())